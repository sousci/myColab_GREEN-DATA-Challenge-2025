{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100",
      "mount_file_id": "1Q7k6oChtwP-W6S9QeR1hMLoHo3hL91NJ",
      "authorship_tag": "ABX9TyO2Z2k8aMVpsCO6k7p+bLX5",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sousci/myColab_GREEN-DATA-Challenge-2025/blob/main/20250602.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "A100ä½¿ç”¨"
      ],
      "metadata": {
        "id": "E9g6l0_6GBdi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ğŸ”° Step 0. Colabç”¨ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—"
      ],
      "metadata": {
        "id": "vwcaK0-5Fd5A"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ziKdB-haFE2v",
        "outputId": "c7559b13-d1ce-4267-c31d-ce8f34e47713"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: lightgbm in /usr/local/lib/python3.11/dist-packages (4.5.0)\n",
            "Requirement already satisfied: numpy>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from lightgbm) (2.0.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from lightgbm) (1.15.3)\n"
          ]
        }
      ],
      "source": [
        "!pip install lightgbm"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ğŸ“¥ Step 1. ãƒ‡ãƒ¼ã‚¿ã®èª­ã¿è¾¼ã¿ã¨å‰å‡¦ç†"
      ],
      "metadata": {
        "id": "KV1WkCQKFhaA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿\n",
        "PATH = '/content/drive/MyDrive/SIGNATE/SMBC_Group_GREENDATA_Challenge_2025/'\n",
        "train = pd.read_csv(PATH + 'train.csv')\n",
        "test = pd.read_csv(PATH + 'test.csv')\n",
        "feature_desc = pd.read_csv(PATH + 'feature_description.csv')\n",
        "\n",
        "# å‰å‡¦ç†é–¢æ•°å®šç¾©\n",
        "def preprocess_data(df, is_train=True):\n",
        "    df = df.copy()\n",
        "\n",
        "    # æ™‚åˆ»å¤‰æ›ï¼ˆUTCã‚¿ã‚¤ãƒ ã‚¾ãƒ¼ãƒ³ã«å¤‰æ›ï¼‰\n",
        "    df['time'] = pd.to_datetime(df['time'], utc=True)\n",
        "    df['hour'] = df['time'].dt.hour\n",
        "    df['dayofweek'] = df['time'].dt.dayofweek\n",
        "    df['month'] = df['time'].dt.month\n",
        "    df['is_weekend'] = df['dayofweek'] >= 5\n",
        "\n",
        "    # å¤©æ°—ãªã©ã‚«ãƒ†ã‚´ãƒªã®One-Hotã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°\n",
        "    cat_cols = df.select_dtypes(include='object').columns.tolist()\n",
        "    cat_cols = [col for col in cat_cols if col not in ['time']]\n",
        "    df = pd.get_dummies(df, columns=cat_cols)\n",
        "\n",
        "    # åˆ†å²\n",
        "    if is_train:\n",
        "        y = df['price_actual']\n",
        "        X = df.drop(columns=['time', 'price_actual'])\n",
        "        return X, y\n",
        "    else:\n",
        "        X = df.drop(columns=['time'])\n",
        "        return X\n",
        "\n",
        "# å‰å‡¦ç†å®Ÿè¡Œ\n",
        "X_train, y_train = preprocess_data(train, is_train=True)\n",
        "X_test = preprocess_data(test, is_train=False)"
      ],
      "metadata": {
        "id": "EeEgUqJuFaV9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## âš™ï¸ Step 2. ç‰¹å¾´é‡ã®æ•´åˆæ€§ï¼ˆåˆ—ã®è¿½åŠ ï¼‰"
      ],
      "metadata": {
        "id": "n9ND4ZSAGIY4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã«ä¸è¶³ã—ã¦ã„ã‚‹åˆ—ã‚’è£œå®Œ\n",
        "missing_cols = set(X_train.columns) - set(X_test.columns)\n",
        "for col in missing_cols:\n",
        "    X_test[col] = 0\n",
        "X_test = X_test[X_train.columns]"
      ],
      "metadata": {
        "id": "gOd_E5TeF2BY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ğŸ“Š Step 3. ãƒ¢ãƒ‡ãƒ«ã®å­¦ç¿’ã¨è©•ä¾¡ï¼ˆLightGBM + æ™‚ç³»åˆ—CVï¼‰"
      ],
      "metadata": {
        "id": "wgYpXjK6GPOY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from lightgbm import LGBMRegressor\n",
        "from lightgbm import early_stopping, log_evaluation\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "from sklearn.model_selection import TimeSeriesSplit"
      ],
      "metadata": {
        "id": "zs3Fe_NgGTan"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = LGBMRegressor(\n",
        "    n_estimators=1000,\n",
        "    learning_rate=0.05,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "tscv = TimeSeriesSplit(n_splits=3)\n",
        "val_scores = []\n",
        "\n",
        "for fold, (train_idx, val_idx) in enumerate(tscv.split(X_train)):\n",
        "    X_tr, X_val = X_train.iloc[train_idx], X_train.iloc[val_idx]\n",
        "    y_tr, y_val = y_train.iloc[train_idx], y_train.iloc[val_idx]\n",
        "\n",
        "    model.fit(\n",
        "        X_tr, y_tr,\n",
        "        eval_set=[(X_val, y_val)],\n",
        "        callbacks=[early_stopping(stopping_rounds=50), log_evaluation(100)]\n",
        "    )\n",
        "\n",
        "    y_pred = model.predict(X_val)\n",
        "    mae = mean_absolute_error(y_val, y_pred)\n",
        "    val_scores.append(mae)\n",
        "    print(f\"Fold {fold+1} MAE: {mae:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QGxAvlx7GKL3",
        "outputId": "e431e2eb-3944-4a98-fd2c-c15b632ffe90"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002919 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 10166\n",
            "[LightGBM] [Info] Number of data points in the train set: 6570, number of used features: 231\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Info] Start training from score 61.611324\n",
            "Training until validation scores don't improve for 50 rounds\n",
            "[100]\tvalid_0's l2: 302.737\n",
            "[200]\tvalid_0's l2: 299.851\n",
            "Early stopping, best iteration is:\n",
            "[183]\tvalid_0's l2: 299.064\n",
            "Fold 1 MAE: 14.6870\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002229 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 10512\n",
            "[LightGBM] [Info] Number of data points in the train set: 13140, number of used features: 267\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Info] Start training from score 53.824721\n",
            "Training until validation scores don't improve for 50 rounds\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's l2: 212.736\n",
            "Fold 2 MAE: 10.6451\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010054 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 10685\n",
            "[LightGBM] [Info] Number of data points in the train set: 19710, number of used features: 292\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Info] Start training from score 55.363522\n",
            "Training until validation scores don't improve for 50 rounds\n",
            "[100]\tvalid_0's l2: 46.796\n",
            "[200]\tvalid_0's l2: 44.1428\n",
            "[300]\tvalid_0's l2: 43.4741\n",
            "[400]\tvalid_0's l2: 43.1261\n",
            "Early stopping, best iteration is:\n",
            "[425]\tvalid_0's l2: 42.9852\n",
            "Fold 3 MAE: 5.0332\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ğŸ“¤ Step 4. äºˆæ¸¬ã¨æå‡ºãƒ•ã‚¡ã‚¤ãƒ«ã®ä½œæˆ"
      ],
      "metadata": {
        "id": "de7qdQqGGWaL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿äºˆæ¸¬\n",
        "y_test_pred = model.predict(X_test)\n",
        "\n",
        "# æå‡ºãƒ•ã‚¡ã‚¤ãƒ«ä½œæˆ\n",
        "submit = pd.DataFrame({\n",
        "    \"time\": test['time'],\n",
        "    \"0\": y_test_pred\n",
        "})"
      ],
      "metadata": {
        "id": "iurNCpCYGQsj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: # ä»Šæ—¥ã®æ—¥ä»˜ã¨æ™‚åˆ»ã‚’YYYYMMDDhhmmå½¢å¼ã§ã€'submission_YYYYMMDDhhmm.csv'ã¨ã„ã†åå‰ã§ä¿å­˜\n",
        "\n",
        "from datetime import datetime\n",
        "\n",
        "# ä»Šæ—¥ã®æ—¥ä»˜ã¨æ™‚åˆ»ã‚’å–å¾—\n",
        "now = datetime.now()\n",
        "\n",
        "# ãƒ•ã‚¡ã‚¤ãƒ«åã‚’ç”Ÿæˆ\n",
        "filename = f'submission_{now.strftime(\"%Y%m%d%H%M\")}.csv'\n",
        "\n",
        "# æå‡ºãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä¿å­˜\n",
        "submit.to_csv(PATH + filename, index=False, header=False)"
      ],
      "metadata": {
        "id": "8fY6fwbqGn94"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## âœ… ãƒ¢ãƒ‡ãƒ«è©•ä¾¡ã‚³ãƒ¼ãƒ‰ï¼ˆRMSEï¼‰"
      ],
      "metadata": {
        "id": "YkqGwt8IJkr3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import mean_squared_error\n",
        "import numpy as np\n",
        "\n",
        "# ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³ã‚¹ã‚³ã‚¢ï¼ˆã™ã§ã«å„foldã®MAEã¯ val_scores ã«ä¿å­˜æ¸ˆã¿ï¼‰\n",
        "# RMSEè©•ä¾¡ã®ãŸã‚ã«ã€å†åº¦ TimeSeriesSplit ã‚’ä½¿ã£ã¦äºˆæ¸¬ãƒ»è©•ä¾¡ã‚’è¡Œã†\n",
        "\n",
        "tscv = TimeSeriesSplit(n_splits=3)\n",
        "rmse_scores = []\n",
        "\n",
        "for fold, (train_idx, val_idx) in enumerate(tscv.split(X_train)):\n",
        "    X_tr, X_val = X_train.iloc[train_idx], X_train.iloc[val_idx]\n",
        "    y_tr, y_val = y_train.iloc[train_idx], y_train.iloc[val_idx]\n",
        "\n",
        "    model.fit(\n",
        "        X_tr, y_tr,\n",
        "        eval_set=[(X_val, y_val)],\n",
        "        callbacks=[early_stopping(stopping_rounds=50), log_evaluation(100)]\n",
        "    )\n",
        "\n",
        "    y_pred = model.predict(X_val)\n",
        "    rmse = np.sqrt(mean_squared_error(y_val, y_pred))\n",
        "    rmse_scores.append(rmse)\n",
        "    print(f\"Fold {fold+1} RMSE: {rmse:.4f}\")\n",
        "\n",
        "# å…¨ä½“ã®å¹³å‡RMSE\n",
        "print(f\"\\nâœ… å¹³å‡RMSE: {np.mean(rmse_scores):.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J-0wOf3AGrHK",
        "outputId": "e0044cff-d37c-43ae-b727-554a2d3f0c8f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004166 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 10166\n",
            "[LightGBM] [Info] Number of data points in the train set: 6570, number of used features: 231\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Info] Start training from score 61.611324\n",
            "Training until validation scores don't improve for 50 rounds\n",
            "[100]\tvalid_0's l2: 302.737\n",
            "[200]\tvalid_0's l2: 299.851\n",
            "Early stopping, best iteration is:\n",
            "[183]\tvalid_0's l2: 299.064\n",
            "Fold 1 RMSE: 17.2935\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008799 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 10512\n",
            "[LightGBM] [Info] Number of data points in the train set: 13140, number of used features: 267\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Info] Start training from score 53.824721\n",
            "Training until validation scores don't improve for 50 rounds\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's l2: 212.736\n",
            "Fold 2 RMSE: 14.5855\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002352 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 10685\n",
            "[LightGBM] [Info] Number of data points in the train set: 19710, number of used features: 292\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Info] Start training from score 55.363522\n",
            "Training until validation scores don't improve for 50 rounds\n",
            "[100]\tvalid_0's l2: 46.796\n",
            "[200]\tvalid_0's l2: 44.1428\n",
            "[300]\tvalid_0's l2: 43.4741\n",
            "[400]\tvalid_0's l2: 43.1261\n",
            "Early stopping, best iteration is:\n",
            "[425]\tvalid_0's l2: 42.9852\n",
            "Fold 3 RMSE: 6.5563\n",
            "\n",
            "âœ… å¹³å‡RMSE: 12.8118\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "UtfF46hJJi2s"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}