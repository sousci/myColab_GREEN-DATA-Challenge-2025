{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100",
      "mount_file_id": "1Q7k6oChtwP-W6S9QeR1hMLoHo3hL91NJ",
      "authorship_tag": "ABX9TyOpSrJOr1oeigWCjrS5zwVO",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sousci/myColab_GREEN-DATA-Challenge-2025/blob/main/20250602.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "A100‰ΩøÁî®"
      ],
      "metadata": {
        "id": "E9g6l0_6GBdi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üî∞ Step 0. ColabÁî®„Çª„ÉÉ„Éà„Ç¢„ÉÉ„Éó"
      ],
      "metadata": {
        "id": "vwcaK0-5Fd5A"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ziKdB-haFE2v",
        "outputId": "a69f743a-a90f-4cb4-8892-552ab80001d5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: lightgbm in /usr/local/lib/python3.11/dist-packages (4.5.0)\n",
            "Requirement already satisfied: numpy>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from lightgbm) (2.0.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from lightgbm) (1.15.3)\n"
          ]
        }
      ],
      "source": [
        "!pip install lightgbm"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üì• Step 1. „Éá„Éº„Çø„ÅÆË™≠„ÅøËæº„Åø„Å®ÂâçÂá¶ÁêÜ"
      ],
      "metadata": {
        "id": "KV1WkCQKFhaA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# „Éá„Éº„ÇøË™≠„ÅøËæº„Åø\n",
        "PATH = '/content/drive/MyDrive/SIGNATE/SMBC_Group_GREENDATA_Challenge_2025/'\n",
        "train = pd.read_csv(PATH + 'train.csv')\n",
        "test = pd.read_csv(PATH + 'test.csv')\n",
        "feature_desc = pd.read_csv(PATH + 'feature_description.csv')"
      ],
      "metadata": {
        "id": "EeEgUqJuFaV9"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# train„ÅÆÂâçÂá¶ÁêÜÔºàprice_actual„ÅØÈô§„ÅèÔºâ\n",
        "train_sorted = train.sort_values(\"time\").reset_index(drop=True)\n",
        "numeric_cols = train_sorted.select_dtypes(include='number').columns.tolist()\n",
        "numeric_cols.remove(\"price_actual\")  # ÁõÆÁöÑÂ§âÊï∞„ÅØÈô§Â§ñ\n",
        "\n",
        "# expandingÊ®ôÊ∫ñÂåñ„ÅÆÈÅ©Áî®\n",
        "for col in numeric_cols:\n",
        "    train_sorted[f\"{col}_mean_to_t\"] = train_sorted[col].expanding().mean()\n",
        "    train_sorted[f\"{col}_std_to_t\"] = train_sorted[col].expanding().std(ddof=0)\n",
        "    train_sorted[f\"{col}_scaled\"] = (\n",
        "        (train_sorted[col] - train_sorted[f\"{col}_mean_to_t\"]) /\n",
        "        train_sorted[f\"{col}_std_to_t\"]\n",
        "    )\n",
        "\n",
        "# Ê®ôÊ∫ñÂåñÊ∏à„Åø„ÅÆÁâπÂæ¥ÈáèÂêçÔºàÁõÆÁöÑÂ§âÊï∞„ÅØ„Åù„ÅÆ„Åæ„ÅæÔºâ\n",
        "scaled_cols = [f\"{col}_scaled\" for col in numeric_cols]\n",
        "train_scaled = train_sorted[['time'] + scaled_cols + ['price_actual']]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yZc1RjVQV_o1",
        "outputId": "6d55458f-351e-4bc9-eca4-245915138080"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-194d552869af>:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_sorted[f\"{col}_std_to_t\"] = train_sorted[col].expanding().std(ddof=0)\n",
            "<ipython-input-3-194d552869af>:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_sorted[f\"{col}_scaled\"] = (\n",
            "<ipython-input-3-194d552869af>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_sorted[f\"{col}_mean_to_t\"] = train_sorted[col].expanding().mean()\n",
            "<ipython-input-3-194d552869af>:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_sorted[f\"{col}_std_to_t\"] = train_sorted[col].expanding().std(ddof=0)\n",
            "<ipython-input-3-194d552869af>:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_sorted[f\"{col}_scaled\"] = (\n",
            "<ipython-input-3-194d552869af>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_sorted[f\"{col}_mean_to_t\"] = train_sorted[col].expanding().mean()\n",
            "<ipython-input-3-194d552869af>:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_sorted[f\"{col}_std_to_t\"] = train_sorted[col].expanding().std(ddof=0)\n",
            "<ipython-input-3-194d552869af>:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_sorted[f\"{col}_scaled\"] = (\n",
            "<ipython-input-3-194d552869af>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_sorted[f\"{col}_mean_to_t\"] = train_sorted[col].expanding().mean()\n",
            "<ipython-input-3-194d552869af>:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_sorted[f\"{col}_std_to_t\"] = train_sorted[col].expanding().std(ddof=0)\n",
            "<ipython-input-3-194d552869af>:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_sorted[f\"{col}_scaled\"] = (\n",
            "<ipython-input-3-194d552869af>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_sorted[f\"{col}_mean_to_t\"] = train_sorted[col].expanding().mean()\n",
            "<ipython-input-3-194d552869af>:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_sorted[f\"{col}_std_to_t\"] = train_sorted[col].expanding().std(ddof=0)\n",
            "<ipython-input-3-194d552869af>:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_sorted[f\"{col}_scaled\"] = (\n",
            "<ipython-input-3-194d552869af>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_sorted[f\"{col}_mean_to_t\"] = train_sorted[col].expanding().mean()\n",
            "<ipython-input-3-194d552869af>:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_sorted[f\"{col}_std_to_t\"] = train_sorted[col].expanding().std(ddof=0)\n",
            "<ipython-input-3-194d552869af>:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_sorted[f\"{col}_scaled\"] = (\n",
            "<ipython-input-3-194d552869af>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_sorted[f\"{col}_mean_to_t\"] = train_sorted[col].expanding().mean()\n",
            "<ipython-input-3-194d552869af>:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_sorted[f\"{col}_std_to_t\"] = train_sorted[col].expanding().std(ddof=0)\n",
            "<ipython-input-3-194d552869af>:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_sorted[f\"{col}_scaled\"] = (\n",
            "<ipython-input-3-194d552869af>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_sorted[f\"{col}_mean_to_t\"] = train_sorted[col].expanding().mean()\n",
            "<ipython-input-3-194d552869af>:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_sorted[f\"{col}_std_to_t\"] = train_sorted[col].expanding().std(ddof=0)\n",
            "<ipython-input-3-194d552869af>:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_sorted[f\"{col}_scaled\"] = (\n",
            "<ipython-input-3-194d552869af>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_sorted[f\"{col}_mean_to_t\"] = train_sorted[col].expanding().mean()\n",
            "<ipython-input-3-194d552869af>:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_sorted[f\"{col}_std_to_t\"] = train_sorted[col].expanding().std(ddof=0)\n",
            "<ipython-input-3-194d552869af>:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_sorted[f\"{col}_scaled\"] = (\n",
            "<ipython-input-3-194d552869af>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_sorted[f\"{col}_mean_to_t\"] = train_sorted[col].expanding().mean()\n",
            "<ipython-input-3-194d552869af>:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_sorted[f\"{col}_std_to_t\"] = train_sorted[col].expanding().std(ddof=0)\n",
            "<ipython-input-3-194d552869af>:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_sorted[f\"{col}_scaled\"] = (\n",
            "<ipython-input-3-194d552869af>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_sorted[f\"{col}_mean_to_t\"] = train_sorted[col].expanding().mean()\n",
            "<ipython-input-3-194d552869af>:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_sorted[f\"{col}_std_to_t\"] = train_sorted[col].expanding().std(ddof=0)\n",
            "<ipython-input-3-194d552869af>:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_sorted[f\"{col}_scaled\"] = (\n",
            "<ipython-input-3-194d552869af>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_sorted[f\"{col}_mean_to_t\"] = train_sorted[col].expanding().mean()\n",
            "<ipython-input-3-194d552869af>:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_sorted[f\"{col}_std_to_t\"] = train_sorted[col].expanding().std(ddof=0)\n",
            "<ipython-input-3-194d552869af>:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_sorted[f\"{col}_scaled\"] = (\n",
            "<ipython-input-3-194d552869af>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_sorted[f\"{col}_mean_to_t\"] = train_sorted[col].expanding().mean()\n",
            "<ipython-input-3-194d552869af>:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_sorted[f\"{col}_std_to_t\"] = train_sorted[col].expanding().std(ddof=0)\n",
            "<ipython-input-3-194d552869af>:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_sorted[f\"{col}_scaled\"] = (\n",
            "<ipython-input-3-194d552869af>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_sorted[f\"{col}_mean_to_t\"] = train_sorted[col].expanding().mean()\n",
            "<ipython-input-3-194d552869af>:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_sorted[f\"{col}_std_to_t\"] = train_sorted[col].expanding().std(ddof=0)\n",
            "<ipython-input-3-194d552869af>:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_sorted[f\"{col}_scaled\"] = (\n",
            "<ipython-input-3-194d552869af>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_sorted[f\"{col}_mean_to_t\"] = train_sorted[col].expanding().mean()\n",
            "<ipython-input-3-194d552869af>:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_sorted[f\"{col}_std_to_t\"] = train_sorted[col].expanding().std(ddof=0)\n",
            "<ipython-input-3-194d552869af>:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_sorted[f\"{col}_scaled\"] = (\n",
            "<ipython-input-3-194d552869af>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_sorted[f\"{col}_mean_to_t\"] = train_sorted[col].expanding().mean()\n",
            "<ipython-input-3-194d552869af>:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_sorted[f\"{col}_std_to_t\"] = train_sorted[col].expanding().std(ddof=0)\n",
            "<ipython-input-3-194d552869af>:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_sorted[f\"{col}_scaled\"] = (\n",
            "<ipython-input-3-194d552869af>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_sorted[f\"{col}_mean_to_t\"] = train_sorted[col].expanding().mean()\n",
            "<ipython-input-3-194d552869af>:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_sorted[f\"{col}_std_to_t\"] = train_sorted[col].expanding().std(ddof=0)\n",
            "<ipython-input-3-194d552869af>:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_sorted[f\"{col}_scaled\"] = (\n",
            "<ipython-input-3-194d552869af>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_sorted[f\"{col}_mean_to_t\"] = train_sorted[col].expanding().mean()\n",
            "<ipython-input-3-194d552869af>:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_sorted[f\"{col}_std_to_t\"] = train_sorted[col].expanding().std(ddof=0)\n",
            "<ipython-input-3-194d552869af>:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_sorted[f\"{col}_scaled\"] = (\n",
            "<ipython-input-3-194d552869af>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_sorted[f\"{col}_mean_to_t\"] = train_sorted[col].expanding().mean()\n",
            "<ipython-input-3-194d552869af>:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_sorted[f\"{col}_std_to_t\"] = train_sorted[col].expanding().std(ddof=0)\n",
            "<ipython-input-3-194d552869af>:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_sorted[f\"{col}_scaled\"] = (\n",
            "<ipython-input-3-194d552869af>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_sorted[f\"{col}_mean_to_t\"] = train_sorted[col].expanding().mean()\n",
            "<ipython-input-3-194d552869af>:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_sorted[f\"{col}_std_to_t\"] = train_sorted[col].expanding().std(ddof=0)\n",
            "<ipython-input-3-194d552869af>:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_sorted[f\"{col}_scaled\"] = (\n",
            "<ipython-input-3-194d552869af>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_sorted[f\"{col}_mean_to_t\"] = train_sorted[col].expanding().mean()\n",
            "<ipython-input-3-194d552869af>:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_sorted[f\"{col}_std_to_t\"] = train_sorted[col].expanding().std(ddof=0)\n",
            "<ipython-input-3-194d552869af>:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_sorted[f\"{col}_scaled\"] = (\n",
            "<ipython-input-3-194d552869af>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_sorted[f\"{col}_mean_to_t\"] = train_sorted[col].expanding().mean()\n",
            "<ipython-input-3-194d552869af>:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_sorted[f\"{col}_std_to_t\"] = train_sorted[col].expanding().std(ddof=0)\n",
            "<ipython-input-3-194d552869af>:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_sorted[f\"{col}_scaled\"] = (\n",
            "<ipython-input-3-194d552869af>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_sorted[f\"{col}_mean_to_t\"] = train_sorted[col].expanding().mean()\n",
            "<ipython-input-3-194d552869af>:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_sorted[f\"{col}_std_to_t\"] = train_sorted[col].expanding().std(ddof=0)\n",
            "<ipython-input-3-194d552869af>:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_sorted[f\"{col}_scaled\"] = (\n",
            "<ipython-input-3-194d552869af>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_sorted[f\"{col}_mean_to_t\"] = train_sorted[col].expanding().mean()\n",
            "<ipython-input-3-194d552869af>:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_sorted[f\"{col}_std_to_t\"] = train_sorted[col].expanding().std(ddof=0)\n",
            "<ipython-input-3-194d552869af>:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_sorted[f\"{col}_scaled\"] = (\n",
            "<ipython-input-3-194d552869af>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_sorted[f\"{col}_mean_to_t\"] = train_sorted[col].expanding().mean()\n",
            "<ipython-input-3-194d552869af>:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_sorted[f\"{col}_std_to_t\"] = train_sorted[col].expanding().std(ddof=0)\n",
            "<ipython-input-3-194d552869af>:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_sorted[f\"{col}_scaled\"] = (\n",
            "<ipython-input-3-194d552869af>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_sorted[f\"{col}_mean_to_t\"] = train_sorted[col].expanding().mean()\n",
            "<ipython-input-3-194d552869af>:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_sorted[f\"{col}_std_to_t\"] = train_sorted[col].expanding().std(ddof=0)\n",
            "<ipython-input-3-194d552869af>:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_sorted[f\"{col}_scaled\"] = (\n",
            "<ipython-input-3-194d552869af>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_sorted[f\"{col}_mean_to_t\"] = train_sorted[col].expanding().mean()\n",
            "<ipython-input-3-194d552869af>:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_sorted[f\"{col}_std_to_t\"] = train_sorted[col].expanding().std(ddof=0)\n",
            "<ipython-input-3-194d552869af>:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_sorted[f\"{col}_scaled\"] = (\n",
            "<ipython-input-3-194d552869af>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_sorted[f\"{col}_mean_to_t\"] = train_sorted[col].expanding().mean()\n",
            "<ipython-input-3-194d552869af>:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_sorted[f\"{col}_std_to_t\"] = train_sorted[col].expanding().std(ddof=0)\n",
            "<ipython-input-3-194d552869af>:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_sorted[f\"{col}_scaled\"] = (\n",
            "<ipython-input-3-194d552869af>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_sorted[f\"{col}_mean_to_t\"] = train_sorted[col].expanding().mean()\n",
            "<ipython-input-3-194d552869af>:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_sorted[f\"{col}_std_to_t\"] = train_sorted[col].expanding().std(ddof=0)\n",
            "<ipython-input-3-194d552869af>:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_sorted[f\"{col}_scaled\"] = (\n",
            "<ipython-input-3-194d552869af>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_sorted[f\"{col}_mean_to_t\"] = train_sorted[col].expanding().mean()\n",
            "<ipython-input-3-194d552869af>:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_sorted[f\"{col}_std_to_t\"] = train_sorted[col].expanding().std(ddof=0)\n",
            "<ipython-input-3-194d552869af>:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_sorted[f\"{col}_scaled\"] = (\n",
            "<ipython-input-3-194d552869af>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_sorted[f\"{col}_mean_to_t\"] = train_sorted[col].expanding().mean()\n",
            "<ipython-input-3-194d552869af>:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_sorted[f\"{col}_std_to_t\"] = train_sorted[col].expanding().std(ddof=0)\n",
            "<ipython-input-3-194d552869af>:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_sorted[f\"{col}_scaled\"] = (\n",
            "<ipython-input-3-194d552869af>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_sorted[f\"{col}_mean_to_t\"] = train_sorted[col].expanding().mean()\n",
            "<ipython-input-3-194d552869af>:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_sorted[f\"{col}_std_to_t\"] = train_sorted[col].expanding().std(ddof=0)\n",
            "<ipython-input-3-194d552869af>:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_sorted[f\"{col}_scaled\"] = (\n",
            "<ipython-input-3-194d552869af>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_sorted[f\"{col}_mean_to_t\"] = train_sorted[col].expanding().mean()\n",
            "<ipython-input-3-194d552869af>:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_sorted[f\"{col}_std_to_t\"] = train_sorted[col].expanding().std(ddof=0)\n",
            "<ipython-input-3-194d552869af>:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_sorted[f\"{col}_scaled\"] = (\n",
            "<ipython-input-3-194d552869af>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_sorted[f\"{col}_mean_to_t\"] = train_sorted[col].expanding().mean()\n",
            "<ipython-input-3-194d552869af>:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_sorted[f\"{col}_std_to_t\"] = train_sorted[col].expanding().std(ddof=0)\n",
            "<ipython-input-3-194d552869af>:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_sorted[f\"{col}_scaled\"] = (\n",
            "<ipython-input-3-194d552869af>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_sorted[f\"{col}_mean_to_t\"] = train_sorted[col].expanding().mean()\n",
            "<ipython-input-3-194d552869af>:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_sorted[f\"{col}_std_to_t\"] = train_sorted[col].expanding().std(ddof=0)\n",
            "<ipython-input-3-194d552869af>:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_sorted[f\"{col}_scaled\"] = (\n",
            "<ipython-input-3-194d552869af>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_sorted[f\"{col}_mean_to_t\"] = train_sorted[col].expanding().mean()\n",
            "<ipython-input-3-194d552869af>:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_sorted[f\"{col}_std_to_t\"] = train_sorted[col].expanding().std(ddof=0)\n",
            "<ipython-input-3-194d552869af>:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_sorted[f\"{col}_scaled\"] = (\n",
            "<ipython-input-3-194d552869af>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_sorted[f\"{col}_mean_to_t\"] = train_sorted[col].expanding().mean()\n",
            "<ipython-input-3-194d552869af>:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_sorted[f\"{col}_std_to_t\"] = train_sorted[col].expanding().std(ddof=0)\n",
            "<ipython-input-3-194d552869af>:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_sorted[f\"{col}_scaled\"] = (\n",
            "<ipython-input-3-194d552869af>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_sorted[f\"{col}_mean_to_t\"] = train_sorted[col].expanding().mean()\n",
            "<ipython-input-3-194d552869af>:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_sorted[f\"{col}_std_to_t\"] = train_sorted[col].expanding().std(ddof=0)\n",
            "<ipython-input-3-194d552869af>:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_sorted[f\"{col}_scaled\"] = (\n",
            "<ipython-input-3-194d552869af>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_sorted[f\"{col}_mean_to_t\"] = train_sorted[col].expanding().mean()\n",
            "<ipython-input-3-194d552869af>:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_sorted[f\"{col}_std_to_t\"] = train_sorted[col].expanding().std(ddof=0)\n",
            "<ipython-input-3-194d552869af>:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_sorted[f\"{col}_scaled\"] = (\n",
            "<ipython-input-3-194d552869af>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_sorted[f\"{col}_mean_to_t\"] = train_sorted[col].expanding().mean()\n",
            "<ipython-input-3-194d552869af>:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_sorted[f\"{col}_std_to_t\"] = train_sorted[col].expanding().std(ddof=0)\n",
            "<ipython-input-3-194d552869af>:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_sorted[f\"{col}_scaled\"] = (\n",
            "<ipython-input-3-194d552869af>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_sorted[f\"{col}_mean_to_t\"] = train_sorted[col].expanding().mean()\n",
            "<ipython-input-3-194d552869af>:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_sorted[f\"{col}_std_to_t\"] = train_sorted[col].expanding().std(ddof=0)\n",
            "<ipython-input-3-194d552869af>:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_sorted[f\"{col}_scaled\"] = (\n",
            "<ipython-input-3-194d552869af>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_sorted[f\"{col}_mean_to_t\"] = train_sorted[col].expanding().mean()\n",
            "<ipython-input-3-194d552869af>:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_sorted[f\"{col}_std_to_t\"] = train_sorted[col].expanding().std(ddof=0)\n",
            "<ipython-input-3-194d552869af>:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_sorted[f\"{col}_scaled\"] = (\n",
            "<ipython-input-3-194d552869af>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_sorted[f\"{col}_mean_to_t\"] = train_sorted[col].expanding().mean()\n",
            "<ipython-input-3-194d552869af>:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_sorted[f\"{col}_std_to_t\"] = train_sorted[col].expanding().std(ddof=0)\n",
            "<ipython-input-3-194d552869af>:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  train_sorted[f\"{col}_scaled\"] = (\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# test„ÅÆÂâçÂá¶ÁêÜ\n",
        "test_sorted = test.sort_values(\"time\").reset_index(drop=True)\n",
        "\n",
        "# train„ÅÆÊúÄÁµÇÊôÇÁÇπ„ÅÆÂπ≥Âùá„ÉªÊ®ôÊ∫ñÂÅèÂ∑Æ„Çí‰Ωø„Å£„Å¶Ê®ôÊ∫ñÂåñ\n",
        "for col in numeric_cols:\n",
        "    mu = train_sorted[f\"{col}_mean_to_t\"].iloc[-1]\n",
        "    std = train_sorted[f\"{col}_std_to_t\"].iloc[-1]\n",
        "    test_sorted[f\"{col}_scaled\"] = (test_sorted[col] - mu) / std\n",
        "\n",
        "test_scaled = test_sorted[['time'] + [f\"{col}_scaled\" for col in numeric_cols]]"
      ],
      "metadata": {
        "id": "NLPuCv74WEH8"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ‰æãÔºöÊ®ôÊ∫ñÂåñÂæå„ÅÆÊúÄÂàù„ÅÆÊï∞Ë°å„ÇíË°®Á§∫\n",
        "train_scaled.head()\n",
        "test_scaled.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 342
        },
        "id": "VQ5v5hDZWFib",
        "outputId": "508e69d8-5918-4870-9eb7-c23676d89613"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                        time  generation_biomass_scaled  \\\n",
              "0  2018-01-01 00:00:00+01:00                  -1.336571   \n",
              "1  2018-01-01 01:00:00+01:00                  -1.303199   \n",
              "2  2018-01-01 02:00:00+01:00                  -1.292075   \n",
              "3  2018-01-01 03:00:00+01:00                  -1.325447   \n",
              "4  2018-01-01 04:00:00+01:00                  -1.258703   \n",
              "\n",
              "   generation_fossil_brown_coal/lignite_scaled  generation_fossil_gas_scaled  \\\n",
              "0                                    -1.314607                     -0.718683   \n",
              "1                                    -1.314607                     -0.709440   \n",
              "2                                    -1.314607                     -0.778543   \n",
              "3                                    -1.314607                     -0.831361   \n",
              "4                                    -1.314607                     -0.924232   \n",
              "\n",
              "   generation_fossil_hard_coal_scaled  generation_fossil_oil_scaled  \\\n",
              "0                           -1.751850                     -2.124644   \n",
              "1                           -1.760234                     -2.346720   \n",
              "2                           -1.754316                     -2.383733   \n",
              "3                           -1.758754                     -2.383733   \n",
              "4                           -1.768617                     -2.420746   \n",
              "\n",
              "   generation_hydro_pumped_storage_consumption_scaled  \\\n",
              "0                                          -0.340835    \n",
              "1                                           0.950081    \n",
              "2                                           2.103083    \n",
              "3                                           3.057292    \n",
              "4                                           2.734253    \n",
              "\n",
              "   generation_hydro_run_of_river_and_poundage_scaled  \\\n",
              "0                                           0.489439   \n",
              "1                                           0.459670   \n",
              "2                                           0.443432   \n",
              "3                                           0.389305   \n",
              "4                                           0.305408   \n",
              "\n",
              "   generation_hydro_water_reservoir_scaled  generation_nuclear_scaled  ...  \\\n",
              "0                                -0.328923                   0.942500  ...   \n",
              "1                                -0.793849                   0.938877  ...   \n",
              "2                                -0.866611                   0.937669  ...   \n",
              "3                                -0.996619                   0.938877  ...   \n",
              "4                                -0.988059                   0.938877  ...   \n",
              "\n",
              "   seville_temp_max_scaled  seville_pressure_scaled  seville_humidity_scaled  \\\n",
              "0                -1.252996                 2.011949                 1.044069   \n",
              "1                -1.474023                 2.158002                 1.044069   \n",
              "2                -1.584536                 2.158002                 1.044069   \n",
              "3                -1.695049                 2.158002                 1.301429   \n",
              "4                -1.584536                 2.158002                 1.044069   \n",
              "\n",
              "   seville_wind_speed_scaled  seville_wind_deg_scaled  seville_rain_1h_scaled  \\\n",
              "0                  -0.774331                 1.855445               -0.192788   \n",
              "1                  -0.774331                 1.855445               -0.192788   \n",
              "2                  -0.774331                -1.434192               -0.192788   \n",
              "3                  -0.774331                -1.050561               -0.192788   \n",
              "4                  -0.774331                -1.146469               -0.192788   \n",
              "\n",
              "   seville_rain_3h_scaled  seville_snow_3h_scaled  seville_clouds_all_scaled  \\\n",
              "0               -0.061253                     NaN                  -0.532556   \n",
              "1               -0.061253                     NaN                  -0.532556   \n",
              "2               -0.061253                     NaN                  -0.532556   \n",
              "3               -0.061253                     NaN                  -0.532556   \n",
              "4               -0.061253                     NaN                  -0.532556   \n",
              "\n",
              "   seville_weather_id_scaled  \n",
              "0                   0.301183  \n",
              "1                   0.301183  \n",
              "2                   0.301183  \n",
              "3                   0.301183  \n",
              "4                   0.301183  \n",
              "\n",
              "[5 rows x 76 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-10be3143-ef70-429a-8593-aa5d9d2e65d0\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>time</th>\n",
              "      <th>generation_biomass_scaled</th>\n",
              "      <th>generation_fossil_brown_coal/lignite_scaled</th>\n",
              "      <th>generation_fossil_gas_scaled</th>\n",
              "      <th>generation_fossil_hard_coal_scaled</th>\n",
              "      <th>generation_fossil_oil_scaled</th>\n",
              "      <th>generation_hydro_pumped_storage_consumption_scaled</th>\n",
              "      <th>generation_hydro_run_of_river_and_poundage_scaled</th>\n",
              "      <th>generation_hydro_water_reservoir_scaled</th>\n",
              "      <th>generation_nuclear_scaled</th>\n",
              "      <th>...</th>\n",
              "      <th>seville_temp_max_scaled</th>\n",
              "      <th>seville_pressure_scaled</th>\n",
              "      <th>seville_humidity_scaled</th>\n",
              "      <th>seville_wind_speed_scaled</th>\n",
              "      <th>seville_wind_deg_scaled</th>\n",
              "      <th>seville_rain_1h_scaled</th>\n",
              "      <th>seville_rain_3h_scaled</th>\n",
              "      <th>seville_snow_3h_scaled</th>\n",
              "      <th>seville_clouds_all_scaled</th>\n",
              "      <th>seville_weather_id_scaled</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2018-01-01 00:00:00+01:00</td>\n",
              "      <td>-1.336571</td>\n",
              "      <td>-1.314607</td>\n",
              "      <td>-0.718683</td>\n",
              "      <td>-1.751850</td>\n",
              "      <td>-2.124644</td>\n",
              "      <td>-0.340835</td>\n",
              "      <td>0.489439</td>\n",
              "      <td>-0.328923</td>\n",
              "      <td>0.942500</td>\n",
              "      <td>...</td>\n",
              "      <td>-1.252996</td>\n",
              "      <td>2.011949</td>\n",
              "      <td>1.044069</td>\n",
              "      <td>-0.774331</td>\n",
              "      <td>1.855445</td>\n",
              "      <td>-0.192788</td>\n",
              "      <td>-0.061253</td>\n",
              "      <td>NaN</td>\n",
              "      <td>-0.532556</td>\n",
              "      <td>0.301183</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2018-01-01 01:00:00+01:00</td>\n",
              "      <td>-1.303199</td>\n",
              "      <td>-1.314607</td>\n",
              "      <td>-0.709440</td>\n",
              "      <td>-1.760234</td>\n",
              "      <td>-2.346720</td>\n",
              "      <td>0.950081</td>\n",
              "      <td>0.459670</td>\n",
              "      <td>-0.793849</td>\n",
              "      <td>0.938877</td>\n",
              "      <td>...</td>\n",
              "      <td>-1.474023</td>\n",
              "      <td>2.158002</td>\n",
              "      <td>1.044069</td>\n",
              "      <td>-0.774331</td>\n",
              "      <td>1.855445</td>\n",
              "      <td>-0.192788</td>\n",
              "      <td>-0.061253</td>\n",
              "      <td>NaN</td>\n",
              "      <td>-0.532556</td>\n",
              "      <td>0.301183</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2018-01-01 02:00:00+01:00</td>\n",
              "      <td>-1.292075</td>\n",
              "      <td>-1.314607</td>\n",
              "      <td>-0.778543</td>\n",
              "      <td>-1.754316</td>\n",
              "      <td>-2.383733</td>\n",
              "      <td>2.103083</td>\n",
              "      <td>0.443432</td>\n",
              "      <td>-0.866611</td>\n",
              "      <td>0.937669</td>\n",
              "      <td>...</td>\n",
              "      <td>-1.584536</td>\n",
              "      <td>2.158002</td>\n",
              "      <td>1.044069</td>\n",
              "      <td>-0.774331</td>\n",
              "      <td>-1.434192</td>\n",
              "      <td>-0.192788</td>\n",
              "      <td>-0.061253</td>\n",
              "      <td>NaN</td>\n",
              "      <td>-0.532556</td>\n",
              "      <td>0.301183</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2018-01-01 03:00:00+01:00</td>\n",
              "      <td>-1.325447</td>\n",
              "      <td>-1.314607</td>\n",
              "      <td>-0.831361</td>\n",
              "      <td>-1.758754</td>\n",
              "      <td>-2.383733</td>\n",
              "      <td>3.057292</td>\n",
              "      <td>0.389305</td>\n",
              "      <td>-0.996619</td>\n",
              "      <td>0.938877</td>\n",
              "      <td>...</td>\n",
              "      <td>-1.695049</td>\n",
              "      <td>2.158002</td>\n",
              "      <td>1.301429</td>\n",
              "      <td>-0.774331</td>\n",
              "      <td>-1.050561</td>\n",
              "      <td>-0.192788</td>\n",
              "      <td>-0.061253</td>\n",
              "      <td>NaN</td>\n",
              "      <td>-0.532556</td>\n",
              "      <td>0.301183</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2018-01-01 04:00:00+01:00</td>\n",
              "      <td>-1.258703</td>\n",
              "      <td>-1.314607</td>\n",
              "      <td>-0.924232</td>\n",
              "      <td>-1.768617</td>\n",
              "      <td>-2.420746</td>\n",
              "      <td>2.734253</td>\n",
              "      <td>0.305408</td>\n",
              "      <td>-0.988059</td>\n",
              "      <td>0.938877</td>\n",
              "      <td>...</td>\n",
              "      <td>-1.584536</td>\n",
              "      <td>2.158002</td>\n",
              "      <td>1.044069</td>\n",
              "      <td>-0.774331</td>\n",
              "      <td>-1.146469</td>\n",
              "      <td>-0.192788</td>\n",
              "      <td>-0.061253</td>\n",
              "      <td>NaN</td>\n",
              "      <td>-0.532556</td>\n",
              "      <td>0.301183</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows √ó 76 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-10be3143-ef70-429a-8593-aa5d9d2e65d0')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-10be3143-ef70-429a-8593-aa5d9d2e65d0 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-10be3143-ef70-429a-8593-aa5d9d2e65d0');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-03ad2f01-6dca-482d-9ecf-a8a1cb5ab689\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-03ad2f01-6dca-482d-9ecf-a8a1cb5ab689')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-03ad2f01-6dca-482d-9ecf-a8a1cb5ab689 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "test_scaled"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# üîé Âá¶ÁêÜÂâçÂæå„ÅÆÁâπÂæ¥ÈáèÊßãÊàê„ÅÆÂ§âÂåñ„ÇíÁ¢∫Ë™çÔºà„Çπ„Ç±„Éº„É™„É≥„Ç∞Ê∏à„Éá„Éº„Çø„Å´ÂØæÂøúÔºâ\n",
        "\n",
        "# „Çπ„Ç±„Éº„É™„É≥„Ç∞Ââç„ÅÆÂÖÉ„ÅÆÊï∞ÂÄ§ÂàóÔºàprice_actualÈô§„ÅèÔºâ\n",
        "numeric_cols = train.select_dtypes(include='number').columns.tolist()\n",
        "if \"price_actual\" in numeric_cols:\n",
        "    numeric_cols.remove(\"price_actual\")\n",
        "\n",
        "# „Çπ„Ç±„Éº„É™„É≥„Ç∞Âæå„ÅÆÁâπÂæ¥ÈáèÂêç\n",
        "scaled_cols = [f\"{col}_scaled\" for col in numeric_cols]\n",
        "\n",
        "# ÂÖÉ„ÅÆÁâπÂæ¥ÈáèÊï∞Ôºàtime, price_actualÈô§„ÅÑ„ÅüÊï∞ÂÄ§ÂàóÔºâ\n",
        "original_cols = train.columns.tolist()\n",
        "\n",
        "# „Çπ„Ç±„Éº„É™„É≥„Ç∞Âæå„ÅÆÂÖ®Âàó\n",
        "processed_cols = train_scaled.columns.tolist()\n",
        "\n",
        "# Êñ∞„Åó„ÅèËøΩÂä†„Åï„Çå„ÅüÂàóÔºà„Çπ„Ç±„Éº„É™„É≥„Ç∞ÂàóÔºâ\n",
        "new_cols = list(set(processed_cols) - set(original_cols))\n",
        "\n",
        "# ÂâäÈô§„Åï„Çå„ÅüÂàóÔºàtime‰ª•Â§ñ„ÅØprice_actualÁ®ãÂ∫¶Ôºâ\n",
        "removed_cols = list(set(original_cols) - set(processed_cols))\n",
        "\n",
        "# ÁµêÊûúË°®Á§∫\n",
        "print(f\"üßæ ÂÖÉ„ÅÆÁâπÂæ¥ÈáèÊï∞: {len(original_cols)}\")\n",
        "print(f\"‚úÖ ÂâçÂá¶ÁêÜÂæå„ÅÆÁâπÂæ¥ÈáèÊï∞: {len(processed_cols)}\")\n",
        "print(f\"‚ûï Êñ∞„Åü„Å´ËøΩÂä†„Åï„Çå„ÅüÂàó: {len(new_cols)}\")\n",
        "print(f\"‚ûñ ÂâäÈô§„Åï„Çå„ÅüÂàó: {removed_cols}\")\n",
        "print(f\"üßÆ „Çπ„Ç±„Éº„É™„É≥„Ç∞„Åï„Çå„ÅüÂàóÊï∞: {len(scaled_cols)}\")\n",
        "print(f\"üïí ÊôÇÁ≥ªÂàóÁâπÂæ¥Èáè„ÅØÊú™ËøΩÂä†ÔºàÂøÖË¶Å„Åß„ÅÇ„Çå„Å∞ hour, dayofweek „Å™„Å©„ÇíËøΩÂä†ÂèØÔºâ\")\n",
        "\n",
        "print(\"\\nüéØ Êñ∞Ë¶èËøΩÂä†„Åï„Çå„ÅüÁâπÂæ¥Èáè‰æã:\")\n",
        "print(sorted(new_cols)[:5])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Ah_Cf7_SHG-",
        "outputId": "d2cb5b01-da2d-4b53-908e-43e87380aecc"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üßæ ÂÖÉ„ÅÆÁâπÂæ¥ÈáèÊï∞: 92\n",
            "‚úÖ ÂâçÂá¶ÁêÜÂæå„ÅÆÁâπÂæ¥ÈáèÊï∞: 77\n",
            "‚ûï Êñ∞„Åü„Å´ËøΩÂä†„Åï„Çå„ÅüÂàó: 75\n",
            "‚ûñ ÂâäÈô§„Åï„Çå„ÅüÂàó: ['generation_biomass', 'seville_weather_icon', 'barcelona_rain_3h', 'madrid_weather_icon', 'valencia_weather_description', 'seville_rain_1h', 'barcelona_wind_deg', 'seville_temp_min', 'generation_other_renewable', 'bilbao_temp', 'seville_weather_description', 'generation_fossil_brown_coal/lignite', 'valencia_snow_3h', 'barcelona_weather_id', 'bilbao_weather_description', 'barcelona_weather_description', 'seville_weather_id', 'valencia_temp_min', 'bilbao_weather_id', 'seville_clouds_all', 'generation_wind_onshore', 'valencia_pressure', 'valencia_temp_max', 'total_load_actual', 'bilbao_pressure', 'madrid_temp_min', 'bilbao_wind_deg', 'madrid_clouds_all', 'generation_other', 'seville_rain_3h', 'bilbao_clouds_all', 'valencia_weather_main', 'barcelona_rain_1h', 'seville_wind_speed', 'generation_hydro_water_reservoir', 'barcelona_clouds_all', 'madrid_wind_deg', 'generation_fossil_hard_coal', 'generation_waste', 'valencia_humidity', 'madrid_weather_description', 'barcelona_pressure', 'valencia_rain_1h', 'valencia_clouds_all', 'bilbao_weather_main', 'generation_solar', 'generation_nuclear', 'barcelona_temp_min', 'bilbao_temp_max', 'madrid_weather_id', 'bilbao_snow_3h', 'seville_temp_max', 'valencia_temp', 'generation_fossil_oil', 'valencia_wind_speed', 'barcelona_snow_3h', 'barcelona_humidity', 'seville_weather_main', 'seville_pressure', 'barcelona_temp_max', 'barcelona_temp', 'madrid_temp', 'madrid_temp_max', 'generation_fossil_gas', 'madrid_humidity', 'madrid_rain_1h', 'seville_wind_deg', 'bilbao_rain_3h', 'madrid_weather_main', 'valencia_rain_3h', 'seville_humidity', 'valencia_weather_icon', 'bilbao_rain_1h', 'madrid_wind_speed', 'valencia_wind_deg', 'bilbao_weather_icon', 'seville_snow_3h', 'bilbao_temp_min', 'bilbao_humidity', 'madrid_pressure', 'barcelona_weather_icon', 'seville_temp', 'valencia_weather_id', 'generation_hydro_run_of_river_and_poundage', 'madrid_rain_3h', 'barcelona_weather_main', 'generation_hydro_pumped_storage_consumption', 'madrid_snow_3h', 'barcelona_wind_speed', 'bilbao_wind_speed']\n",
            "üßÆ „Çπ„Ç±„Éº„É™„É≥„Ç∞„Åï„Çå„ÅüÂàóÊï∞: 75\n",
            "üïí ÊôÇÁ≥ªÂàóÁâπÂæ¥Èáè„ÅØÊú™ËøΩÂä†ÔºàÂøÖË¶Å„Åß„ÅÇ„Çå„Å∞ hour, dayofweek „Å™„Å©„ÇíËøΩÂä†ÂèØÔºâ\n",
            "\n",
            "üéØ Êñ∞Ë¶èËøΩÂä†„Åï„Çå„ÅüÁâπÂæ¥Èáè‰æã:\n",
            "['barcelona_clouds_all_scaled', 'barcelona_humidity_scaled', 'barcelona_pressure_scaled', 'barcelona_rain_1h_scaled', 'barcelona_rain_3h_scaled']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# „Çπ„Ç±„Éº„É™„É≥„Ç∞Âæå„ÅÆÁµ±Ë®àÊÉÖÂ†±ÔºàNaN„ÅØÈô§Â§ñÔºâ\n",
        "train_scaled.describe().T[['mean', 'std', 'min', 'max']].dropna().head(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 383
        },
        "id": "UDY_jFtwSVqm",
        "outputId": "9265b6b9-05a3-46b2-f9a0-685859a4cded"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                        mean       std  \\\n",
              "generation_biomass_scaled                          -0.561276  1.029215   \n",
              "generation_fossil_brown_coal/lignite_scaled         0.060930  0.945775   \n",
              "generation_fossil_gas_scaled                        0.265082  1.237393   \n",
              "generation_fossil_hard_coal_scaled                 -0.123404  0.948401   \n",
              "generation_fossil_oil_scaled                       -0.181724  0.896541   \n",
              "generation_hydro_pumped_storage_consumption_scaled -0.078092  0.968559   \n",
              "generation_hydro_run_of_river_and_poundage_scaled  -0.202482  1.051903   \n",
              "generation_hydro_water_reservoir_scaled            -0.168234  1.013943   \n",
              "generation_nuclear_scaled                          -0.010003  0.973666   \n",
              "generation_other_scaled                            -0.411627  1.009756   \n",
              "\n",
              "                                                         min       max  \n",
              "generation_biomass_scaled                          -7.137158  3.459581  \n",
              "generation_fossil_brown_coal/lignite_scaled        -3.121609  5.877341  \n",
              "generation_fossil_gas_scaled                       -2.429652  7.611282  \n",
              "generation_fossil_hard_coal_scaled                 -3.440877  2.917286  \n",
              "generation_fossil_oil_scaled                       -5.579759  3.886432  \n",
              "generation_hydro_pumped_storage_consumption_scaled -2.241498  4.947803  \n",
              "generation_hydro_run_of_river_and_poundage_scaled  -2.790590  3.075007  \n",
              "generation_hydro_water_reservoir_scaled            -1.808765  4.017197  \n",
              "generation_nuclear_scaled                          -9.794592  4.086397  \n",
              "generation_other_scaled                            -4.459204  6.702526  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-6003d859-0da6-418e-9827-96706b021b25\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>mean</th>\n",
              "      <th>std</th>\n",
              "      <th>min</th>\n",
              "      <th>max</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>generation_biomass_scaled</th>\n",
              "      <td>-0.561276</td>\n",
              "      <td>1.029215</td>\n",
              "      <td>-7.137158</td>\n",
              "      <td>3.459581</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>generation_fossil_brown_coal/lignite_scaled</th>\n",
              "      <td>0.060930</td>\n",
              "      <td>0.945775</td>\n",
              "      <td>-3.121609</td>\n",
              "      <td>5.877341</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>generation_fossil_gas_scaled</th>\n",
              "      <td>0.265082</td>\n",
              "      <td>1.237393</td>\n",
              "      <td>-2.429652</td>\n",
              "      <td>7.611282</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>generation_fossil_hard_coal_scaled</th>\n",
              "      <td>-0.123404</td>\n",
              "      <td>0.948401</td>\n",
              "      <td>-3.440877</td>\n",
              "      <td>2.917286</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>generation_fossil_oil_scaled</th>\n",
              "      <td>-0.181724</td>\n",
              "      <td>0.896541</td>\n",
              "      <td>-5.579759</td>\n",
              "      <td>3.886432</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>generation_hydro_pumped_storage_consumption_scaled</th>\n",
              "      <td>-0.078092</td>\n",
              "      <td>0.968559</td>\n",
              "      <td>-2.241498</td>\n",
              "      <td>4.947803</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>generation_hydro_run_of_river_and_poundage_scaled</th>\n",
              "      <td>-0.202482</td>\n",
              "      <td>1.051903</td>\n",
              "      <td>-2.790590</td>\n",
              "      <td>3.075007</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>generation_hydro_water_reservoir_scaled</th>\n",
              "      <td>-0.168234</td>\n",
              "      <td>1.013943</td>\n",
              "      <td>-1.808765</td>\n",
              "      <td>4.017197</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>generation_nuclear_scaled</th>\n",
              "      <td>-0.010003</td>\n",
              "      <td>0.973666</td>\n",
              "      <td>-9.794592</td>\n",
              "      <td>4.086397</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>generation_other_scaled</th>\n",
              "      <td>-0.411627</td>\n",
              "      <td>1.009756</td>\n",
              "      <td>-4.459204</td>\n",
              "      <td>6.702526</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6003d859-0da6-418e-9827-96706b021b25')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-6003d859-0da6-418e-9827-96706b021b25 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-6003d859-0da6-418e-9827-96706b021b25');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-f25319ec-1ff6-4105-95c2-ffa6ae98a534\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-f25319ec-1ff6-4105-95c2-ffa6ae98a534')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-f25319ec-1ff6-4105-95c2-ffa6ae98a534 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"train_scaled\",\n  \"rows\": 10,\n  \"fields\": [\n    {\n      \"column\": \"mean\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.2316981379795966,\n        \"min\": -0.5612756742574191,\n        \"max\": 0.2650821572864915,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          -0.010003297579051306,\n          0.06093006906594144,\n          -0.07809203116713188\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"std\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.09286554081425903,\n        \"min\": 0.896541212337893,\n        \"max\": 1.2373926705232376,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          0.9736661367699512,\n          0.9457753387190202,\n          0.9685588836923614\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"min\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2.543972973600292,\n        \"min\": -9.794592140976638,\n        \"max\": -1.808765269581077,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          -9.794592140976638,\n          -3.121609307025749,\n          -2.2414976126906945\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"max\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.5908620501065198,\n        \"min\": 2.917285677861476,\n        \"max\": 7.611282372914947,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          4.086396938959524,\n          5.877341477553227,\n          4.9478025375058055\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ‚öôÔ∏è Step 2. ÁâπÂæ¥Èáè„ÅÆÊï¥ÂêàÊÄßÔºàÂàó„ÅÆËøΩÂä†Ôºâ"
      ],
      "metadata": {
        "id": "n9ND4ZSAGIY4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ÁâπÂæ¥ÈáèÂàóÔºàÁõÆÁöÑÂ§âÊï∞„Å®ÊôÇÈñì‰ª•Â§ñÔºâ„ÇíÁâπÂÆö\n",
        "scaled_feature_cols = [col for col in train_scaled.columns if col.endswith('_scaled')]\n",
        "\n",
        "# Â≠¶ÁøíÁî®ÁâπÂæ¥Èáè„ÉªÊïôÂ∏´„Éá„Éº„Çø„ÇíÂÆöÁæ©\n",
        "X_train = train_scaled[scaled_feature_cols]\n",
        "y_train = train_scaled['price_actual']\n",
        "\n",
        "# „ÉÜ„Çπ„Éà„Éá„Éº„Çø„Å´„ÇÇ‰∏çË∂≥Âàó„Åå„ÅÇ„Çå„Å∞ËøΩÂä†ÔºàÈÄöÂ∏∏„ÅØ‰∏ÄËá¥„Åó„Å¶„ÅÑ„Çã„ÅØ„ÅöÔºâ\n",
        "X_test = test_scaled[scaled_feature_cols]\n",
        "missing_cols = set(X_train.columns) - set(X_test.columns)\n",
        "for col in missing_cols:\n",
        "    X_test[col] = 0\n",
        "X_test = X_test[X_train.columns]\n"
      ],
      "metadata": {
        "id": "gOd_E5TeF2BY"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üìä Step 3. „É¢„Éá„É´„ÅÆÂ≠¶Áøí„Å®Ë©ï‰æ°ÔºàLightGBM + ÊôÇÁ≥ªÂàóCVÔºâ"
      ],
      "metadata": {
        "id": "wgYpXjK6GPOY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from lightgbm import LGBMRegressor, early_stopping, log_evaluation\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.model_selection import TimeSeriesSplit\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "zs3Fe_NgGTan"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = LGBMRegressor(\n",
        "    n_estimators=1000,\n",
        "    learning_rate=0.05,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "tscv = TimeSeriesSplit(n_splits=3)\n",
        "rmse_scores = []\n",
        "\n",
        "for fold, (train_idx, val_idx) in enumerate(tscv.split(X_train)):\n",
        "    X_tr, X_val = X_train.iloc[train_idx], X_train.iloc[val_idx]\n",
        "    y_tr, y_val = y_train.iloc[train_idx], y_train.iloc[val_idx]\n",
        "\n",
        "    model.fit(\n",
        "        X_tr, y_tr,\n",
        "        eval_set=[(X_val, y_val)],\n",
        "        callbacks=[early_stopping(stopping_rounds=50), log_evaluation(100)]\n",
        "    )\n",
        "\n",
        "    y_pred = model.predict(X_val)\n",
        "    rmse = np.sqrt(mean_squared_error(y_val, y_pred))\n",
        "    rmse_scores.append(rmse)\n",
        "    print(f\"Fold {fold+1} RMSE: {rmse:.4f}\")\n",
        "\n",
        "print(f\"\\n‚úÖ Âπ≥ÂùáRMSE: {np.mean(rmse_scores):.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QGxAvlx7GKL3",
        "outputId": "ab9977b2-c584-45e9-e78d-ab648b5ea3da"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002100 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 18360\n",
            "[LightGBM] [Info] Number of data points in the train set: 6570, number of used features: 72\n",
            "[LightGBM] [Info] Start training from score 61.611324\n",
            "Training until validation scores don't improve for 50 rounds\n",
            "[100]\tvalid_0's l2: 391.82\n",
            "Early stopping, best iteration is:\n",
            "[91]\tvalid_0's l2: 388.982\n",
            "Fold 1 RMSE: 19.7226\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002143 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 18615\n",
            "[LightGBM] [Info] Number of data points in the train set: 13140, number of used features: 73\n",
            "[LightGBM] [Info] Start training from score 53.824721\n",
            "Training until validation scores don't improve for 50 rounds\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's l2: 212.421\n",
            "Fold 2 RMSE: 14.5747\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003154 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 18615\n",
            "[LightGBM] [Info] Number of data points in the train set: 19710, number of used features: 73\n",
            "[LightGBM] [Info] Start training from score 55.363522\n",
            "Training until validation scores don't improve for 50 rounds\n",
            "Early stopping, best iteration is:\n",
            "[48]\tvalid_0's l2: 86.2954\n",
            "Fold 3 RMSE: 9.2895\n",
            "\n",
            "‚úÖ Âπ≥ÂùáRMSE: 14.5289\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üì§ Step 4. ‰∫àÊ∏¨„Å®ÊèêÂá∫„Éï„Ç°„Ç§„É´„ÅÆ‰ΩúÊàê"
      ],
      "metadata": {
        "id": "de7qdQqGGWaL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# „ÉÜ„Çπ„Éà„Éá„Éº„Çø‰∫àÊ∏¨\n",
        "y_test_pred = model.predict(X_test)\n",
        "\n",
        "# ÊèêÂá∫„Éï„Ç°„Ç§„É´‰ΩúÊàê\n",
        "submit = pd.DataFrame({\n",
        "    \"time\": test['time'],\n",
        "    \"0\": y_test_pred\n",
        "})"
      ],
      "metadata": {
        "id": "iurNCpCYGQsj"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: # ‰ªäÊó•„ÅÆÊó•‰ªò„Å®ÊôÇÂàª„ÇíYYYYMMDDhhmmÂΩ¢Âºè„Åß„ÄÅ'submission_YYYYMMDDhhmm.csv'„Å®„ÅÑ„ÅÜÂêçÂâç„Åß‰øùÂ≠ò\n",
        "\n",
        "from datetime import datetime\n",
        "\n",
        "# ‰ªäÊó•„ÅÆÊó•‰ªò„Å®ÊôÇÂàª„ÇíÂèñÂæó\n",
        "now = datetime.now()\n",
        "\n",
        "# „Éï„Ç°„Ç§„É´Âêç„ÇíÁîüÊàê\n",
        "filename = f'submission_{now.strftime(\"%Y%m%d%H%M\")}.csv'\n",
        "\n",
        "# ÊèêÂá∫„Éï„Ç°„Ç§„É´„Çí‰øùÂ≠ò\n",
        "submit.to_csv(PATH + filename, index=False, header=False)"
      ],
      "metadata": {
        "id": "8fY6fwbqGn94"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ‚úÖ „É¢„Éá„É´Ë©ï‰æ°„Ç≥„Éº„ÉâÔºàRMSEÔºâ"
      ],
      "metadata": {
        "id": "YkqGwt8IJkr3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import mean_squared_error\n",
        "import numpy as np\n",
        "\n",
        "# „Éê„É™„Éá„Éº„Ç∑„Éß„É≥„Çπ„Ç≥„Ç¢Ôºà„Åô„Åß„Å´ÂêÑfold„ÅÆMAE„ÅØ val_scores „Å´‰øùÂ≠òÊ∏à„ÅøÔºâ\n",
        "# RMSEË©ï‰æ°„ÅÆ„Åü„ÇÅ„Å´„ÄÅÂÜçÂ∫¶ TimeSeriesSplit „Çí‰Ωø„Å£„Å¶‰∫àÊ∏¨„ÉªË©ï‰æ°„ÇíË°å„ÅÜ\n",
        "\n",
        "tscv = TimeSeriesSplit(n_splits=3)\n",
        "rmse_scores = []\n",
        "\n",
        "for fold, (train_idx, val_idx) in enumerate(tscv.split(X_train)):\n",
        "    X_tr, X_val = X_train.iloc[train_idx], X_train.iloc[val_idx]\n",
        "    y_tr, y_val = y_train.iloc[train_idx], y_train.iloc[val_idx]\n",
        "\n",
        "    model.fit(\n",
        "        X_tr, y_tr,\n",
        "        eval_set=[(X_val, y_val)],\n",
        "        callbacks=[early_stopping(stopping_rounds=50), log_evaluation(100)]\n",
        "    )\n",
        "\n",
        "    y_pred = model.predict(X_val)\n",
        "    rmse = np.sqrt(mean_squared_error(y_val, y_pred))\n",
        "    rmse_scores.append(rmse)\n",
        "    print(f\"Fold {fold+1} RMSE: {rmse:.4f}\")\n",
        "\n",
        "# ÂÖ®‰Ωì„ÅÆÂπ≥ÂùáRMSE\n",
        "print(f\"\\n‚úÖ Âπ≥ÂùáRMSE: {np.mean(rmse_scores):.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J-0wOf3AGrHK",
        "outputId": "3e5f2cfa-4a59-4716-fd58-51f3cc4c0e05"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002054 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 18360\n",
            "[LightGBM] [Info] Number of data points in the train set: 6570, number of used features: 72\n",
            "[LightGBM] [Info] Start training from score 61.611324\n",
            "Training until validation scores don't improve for 50 rounds\n",
            "[100]\tvalid_0's l2: 391.82\n",
            "Early stopping, best iteration is:\n",
            "[91]\tvalid_0's l2: 388.982\n",
            "Fold 1 RMSE: 19.7226\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002231 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 18615\n",
            "[LightGBM] [Info] Number of data points in the train set: 13140, number of used features: 73\n",
            "[LightGBM] [Info] Start training from score 53.824721\n",
            "Training until validation scores don't improve for 50 rounds\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's l2: 212.421\n",
            "Fold 2 RMSE: 14.5747\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003294 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 18615\n",
            "[LightGBM] [Info] Number of data points in the train set: 19710, number of used features: 73\n",
            "[LightGBM] [Info] Start training from score 55.363522\n",
            "Training until validation scores don't improve for 50 rounds\n",
            "Early stopping, best iteration is:\n",
            "[48]\tvalid_0's l2: 86.2954\n",
            "Fold 3 RMSE: 9.2895\n",
            "\n",
            "‚úÖ Âπ≥ÂùáRMSE: 14.5289\n"
          ]
        }
      ]
    }
  ]
}